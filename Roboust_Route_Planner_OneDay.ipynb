{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROBOUST ROUTE PLANNER\n",
    "\n",
    "### Team: SAFJ\n",
    "\n",
    "### Members: Serif Soner Serbest - Jelena Banjac - Fatine Benhsain -  Asli Yorusun\n",
    "\n",
    "This notebook calculates possible routes according to the system inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLE OF CONTENTS\n",
    "\n",
    "#### 1. Data\n",
    "In this section we import modify the dataset \n",
    "#### 2. Confidence Calculation\n",
    "In this section we build necessary functions and dataframes to calculate confidence for a given route\n",
    "#### 3. Connection Graph\n",
    "In this section we calculate the connection graph that shows the reachability of any station pairs.\n",
    "#### 4. Timetable\n",
    "In this section we create timetable that provide information about departure and arrival stations and times for a given day\n",
    "#### 5. Route\n",
    "In this section we calculate each possible routes by using our timetable and connection graph and provide confidence level of the route with confidence calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2018-06-26'\n",
    "hour = '15:00:00'\n",
    "departure_station = 'Zürich HB'\n",
    "arrival_station = 'Zürich Flughafen'\n",
    "# min_confidence_level = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change from one station to another in mins\n",
    "transfer_delay = 5 \n",
    "\n",
    "# average walking speed is assumed to be 4.5 km/h\n",
    "# ref: https://www.quora.com/What-is-the-average-walking-speed-of-a-human\n",
    "# in minutes\n",
    "max_walking_time = 5\n",
    "\n",
    "# m/min which corresponds to 4.5 km/h\n",
    "human_speed = 75 \n",
    "\n",
    "# as meters\n",
    "max_walking_distance = human_speed * max_walking_time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import socket\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "import ast\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import math\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "import random\n",
    "import json\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Layout to be able to see spark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "def fix_layout(width:int=95):\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML('<style>.container { width:' + str(width) + '% !important; }</style>'))\n",
    "    \n",
    "fix_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = getpass.getuser()\n",
    "\n",
    "SPARK_LOCAL = False\n",
    "\n",
    "# on the laptop\n",
    "if not 'iccluster' in socket.gethostname():\n",
    "    # set this to the base spark directory on your system\n",
    "    SPARK_LOCAL = True\n",
    "    \n",
    "    if username == \"fatine\":\n",
    "        spark_home = '/home/fatine/spark-2.4.1-bin-hadoop2.7'\n",
    "        \n",
    "        try:\n",
    "            import findspark\n",
    "            findspark.init(spark_home)\n",
    "        except ModuleNotFoundError as e:\n",
    "            print('Info: {}'.format(e))\n",
    "    elif username == \"soner\":\n",
    "        spark_home = '/home/soner/Desktop/DSLAB2019/spark-2.4.1-bin-hadoop2.7'\n",
    "        \n",
    "        try:\n",
    "            import findspark\n",
    "            findspark.init(spark_home)\n",
    "        except ModuleNotFoundError as e:\n",
    "            print('Info: {}'.format(e))\n",
    "            \n",
    "    elif username == \"jelena\":\n",
    "        pass\n",
    "        \n",
    "    \n",
    "        \n",
    "# cluster\n",
    "if username == \"jbanjac\":\n",
    "    ROOT_PATH = \"/home/jbanjac/robust-journey-planning\"\n",
    "    os.environ['PYSPARK_PYTHON'] = '/opt/anaconda3/bin/python'\n",
    "# local\n",
    "elif username == \"jelena\":\n",
    "    ROOT_PATH = os.getcwd()\n",
    "    os.environ['PYSPARK_PYTHON'] = '/home/jelena/anaconda3/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import unix_timestamp, udf, desc\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler,Normalizer,  PCA,VectorIndexer\n",
    "from pyspark.ml.clustering import KMeans, BisectingKMeans, GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if username == \"jelena\":\n",
    "    spark = (SparkSession \\\n",
    "                .builder \\\n",
    "                .appName('sbb-{0}'.format(getpass.getuser())) \\\n",
    "                .master('local[4]') \\\n",
    "                .config('spark.driver.memory', '10g') \\\n",
    "                .config('spark.executor.memory', '4g') \\\n",
    "                .config('spark.executor.instances', '5') \\\n",
    "                .config('spark.port.maxRetries', '100') \\\n",
    "                .getOrCreate())\n",
    "    CLUSTER_URL = \"hdfs://iccluster042.iccluster.epfl.ch:8020\"\n",
    "\n",
    "elif SPARK_LOCAL:\n",
    "    spark = SparkSession \\\n",
    "                .builder \\\n",
    "                .master(\"local\") \\\n",
    "                .appName(\"roboust-journey-planing\") \\\n",
    "                .config(\"spark.driver.host\", \"localhost\") \\\n",
    "                .getOrCreate()\n",
    "    CLUSTER_URL = \"\"\n",
    "else:\n",
    "    spark = SparkSession \\\n",
    "                .builder \\\n",
    "                .master(\"yarn\") \\\n",
    "                .appName('sbb-{0}'.format(getpass.getuser())) \\\n",
    "                .config('spark.executor.memory', '4g') \\\n",
    "                .config('spark.executor.instances', '5') \\\n",
    "                .config('spark.port.maxRetries', '100') \\\n",
    "                .getOrCreate()\n",
    "    CLUSTER_URL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://tsf-484-wpa-0-089.epfl.ch:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sbb-jelena</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd3cd8cc5f8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataframe of given day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "departure_day = datetime.strptime(date, '%Y-%m-%d')\n",
    "\n",
    "if SPARK_LOCAL:\n",
    "    if username == \"fatine\":\n",
    "        df_departure_day = spark.read.csv(f\"/home/fatine/Documents/Cours Semestre Printemps/Lab in DS/{departure_day.strftime('%Y-%m')}/{departure_day.strftime('%Y-%m-%d')}istdaten.csv\", header=True, sep=';').cache()\n",
    "    elif username == \"soner\":\n",
    "        df_departure_day = spark.read.csv(f\"/home/soner/Desktop/DSLAB2019/Project/{departure_day.strftime('%Y-%m')}/{departure_day.strftime('%Y-%m-%d')}istdaten.csv\", header=True, sep=';').cache()\n",
    "    elif username == \"jelena\":\n",
    "        df_departure_day = spark.read.csv(f\"{CLUSTER_URL}/datasets/sbb/{str(departure_day.year)}/{str(departure_day.month).zfill(2)}/{departure_day.strftime('%Y-%m-%d')}istdaten.csv.bz2\", sep=';', header=True).cache()\n",
    "\n",
    "else:\n",
    "    df_departure_day = spark.read.csv(f\"{CLUSTER_URL}/datasets/sbb/{str(departure_day.year)}/{str(departure_day.month).zfill(2)}/{departure_day.strftime('%Y-%m-%d')}istdaten.csv.bz2\", sep=';', header=True).cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the work easier for us, we translated our column names to English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_departure_day = df_departure_day.withColumnRenamed(\"BETRIEBSTAG\", \"TRIP_DATE\")\\\n",
    "                                    .withColumnRenamed(\"FAHRT_BEZEICHNER\", \"TRIP_ID\")\\\n",
    "                                    .withColumnRenamed(\"BETREIBER_ID\", \"OPERATOR_ID\")\\\n",
    "                                    .withColumnRenamed(\"BETREIBER_ABK\", \"OPERATOR_ABK\")\\\n",
    "                                    .withColumnRenamed(\"BETREIBER_NAME\", \"OPERATOR_NAME\")\\\n",
    "                                    .withColumnRenamed(\"PRODUKT_ID\", \"TRANSPORT_TYPE\")\\\n",
    "                                    .withColumnRenamed(\"LINIEN_ID\", \"TRAIN_ID\")\\\n",
    "                                    .withColumnRenamed(\"LINIEN_TEXT\", \"TRAIN_NAME\")\\\n",
    "                                    .withColumnRenamed(\"UMLAUF_ID\", \"CIRCULATING_ID\")\\\n",
    "                                    .withColumnRenamed(\"VERKEHRSMITTEL_TEXT\", \"SERVICE_TYPE\")\\\n",
    "                                    .withColumnRenamed(\"ZUSATZFAHRT_TF\", \"ADDITIONAL_DRIVING\")\\\n",
    "                                    .withColumnRenamed(\"FAELLT_AUS_TF\", \"FAILED\")\\\n",
    "                                    .withColumnRenamed(\"BPUIC\", \"STATION_ID\")\\\n",
    "                                    .withColumnRenamed(\"HALTESTELLEN_NAME\", \"STATION_NAME\")\\\n",
    "                                    .withColumnRenamed(\"ANKUNFTSZEIT\", \"SCHEDULE_ARRIVE_TIME\")\\\n",
    "                                    .withColumnRenamed(\"AN_PROGNOSE\", \"ACTUAL_ARRIVE_TIME\")\\\n",
    "                                    .withColumnRenamed(\"AN_PROGNOSE_STATUS\", \"ACTUAL_ARRIVE_TIME_STATUS\")\\\n",
    "                                    .withColumnRenamed(\"ABFAHRTSZEIT\", \"SCHEDULE_DEPART_TIME\")\\\n",
    "                                    .withColumnRenamed(\"AB_PROGNOSE\", \"ACTUAL_DEPART_TIME\")\\\n",
    "                                    .withColumnRenamed(\"AB_PROGNOSE_STATUS\", \"ACTUAL_DEPART_TIME_STATUS\")\\\n",
    "                                    .withColumnRenamed(\"DURCHFAHRT_TF\", \"PASSES_BY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TRIP_DATE: string (nullable = true)\n",
      " |-- TRIP_ID: string (nullable = true)\n",
      " |-- OPERATOR_ID: string (nullable = true)\n",
      " |-- OPERATOR_ABK: string (nullable = true)\n",
      " |-- OPERATOR_NAME: string (nullable = true)\n",
      " |-- TRANSPORT_TYPE: string (nullable = true)\n",
      " |-- TRAIN_ID: string (nullable = true)\n",
      " |-- TRAIN_NAME: string (nullable = true)\n",
      " |-- CIRCULATING_ID: string (nullable = true)\n",
      " |-- SERVICE_TYPE: string (nullable = true)\n",
      " |-- ADDITIONAL_DRIVING: string (nullable = true)\n",
      " |-- FAILED: string (nullable = true)\n",
      " |-- STATION_ID: string (nullable = true)\n",
      " |-- STATION_NAME: string (nullable = true)\n",
      " |-- SCHEDULE_ARRIVE_TIME: string (nullable = true)\n",
      " |-- ACTUAL_ARRIVE_TIME: string (nullable = true)\n",
      " |-- ACTUAL_ARRIVE_TIME_STATUS: string (nullable = true)\n",
      " |-- SCHEDULE_DEPART_TIME: string (nullable = true)\n",
      " |-- ACTUAL_DEPART_TIME: string (nullable = true)\n",
      " |-- ACTUAL_DEPART_TIME_STATUS: string (nullable = true)\n",
      " |-- PASSES_BY: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_departure_day.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter Data by stations around Zurich obtained in Distance Analysis notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Zurich stations set\n",
    "with open('distance/zurich_stations_set.pickle', 'rb') as handle:\n",
    "    zurich_stations_set = pickle.load(handle)\n",
    "    \n",
    "df_zurich = df_departure_day.where(F.col(\"STATION_ID\").isin(zurich_stations_set)).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with no arrival time and departure time information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|SCHEDULE_ARRIVE_TIME|SCHEDULE_DEPART_TIME|\n",
      "+--------------------+--------------------+\n",
      "|               16399|               16413|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We check the null values in the departure and arrival times : \n",
    "df_zurich.select([pyspark.sql.functions.count(pyspark.sql.functions.when(F.col(c).isNull(), c)).alias(c) for c in [\"SCHEDULE_ARRIVE_TIME\", \"SCHEDULE_DEPART_TIME\"]]).show()\n",
    "\n",
    "# For now we drop the connections with a null time\n",
    "df_zurich = df_zurich.na.drop(subset=[\"SCHEDULE_ARRIVE_TIME\", \"SCHEDULE_DEPART_TIME\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter Data based on the decisions taken in Data_Analysis notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zurich = df_zurich.filter(\"TRANSPORT_TYPE is not null\")\n",
    "df_zurich = df_zurich.filter(df_zurich.ADDITIONAL_DRIVING==False)\n",
    "df_zurich = df_zurich.filter(df_zurich.FAILED==False)\n",
    "\n",
    "@F.udf\n",
    "def fix_station_name(station_name):\n",
    "    fixed_station_name = station_name.replace(\"�\", \"ü\")\n",
    "    return fixed_station_name\n",
    "\n",
    "df_zurich = df_zurich.withColumn('STATION_NAME', fix_station_name(df_zurich.STATION_NAME))\n",
    "df_zurich = df_zurich.filter(df_zurich.PASSES_BY == False)\n",
    "\n",
    "df_zurich = df_zurich.filter(df_zurich.ACTUAL_ARRIVE_TIME_STATUS != \"UNBEKANNT\")\n",
    "df_zurich = df_zurich.filter(df_zurich.ACTUAL_DEPART_TIME_STATUS != \"UNBEKANNT\")\n",
    "\n",
    "df_zurich = df_zurich.filter(\"ACTUAL_ARRIVE_TIME is not null and SCHEDULE_ARRIVE_TIME is not null\")\n",
    "df_zurich = df_zurich.filter(\"ACTUAL_ARRIVE_TIME is not null and SCHEDULE_ARRIVE_TIME is not null\")\n",
    "df_zurich = df_zurich.filter(\"not(ACTUAL_DEPART_TIME is null and SCHEDULE_DEPART_TIME is null)\")\n",
    "df_zurich = df_zurich.filter(\"ACTUAL_DEPART_TIME is not null and SCHEDULE_DEPART_TIME is not null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIDENCE CALCULATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_arrive = F.unix_timestamp('ACTUAL_ARRIVE_TIME', format='dd.MM.yyyy HH:mm:ss') - F.unix_timestamp('SCHEDULE_ARRIVE_TIME', format='dd.MM.yyyy HH:mm')\n",
    "\n",
    "delay_depart = F.unix_timestamp('ACTUAL_DEPART_TIME', format='dd.MM.yyyy HH:mm:ss') - F.unix_timestamp('SCHEDULE_DEPART_TIME', format='dd.MM.yyyy HH:mm')\n",
    "\n",
    "@F.udf\n",
    "def convert_to_min(delay_sec):\n",
    "    minutes = math.ceil(delay_sec/60)\n",
    "    return minutes\n",
    "\n",
    "@F.udf\n",
    "def convert_to_weekday_1(date):\n",
    "    return str(datetime.strptime(date, '%d.%m.%Y').strftime('%w'))\n",
    "@F.udf\n",
    "def convert_to_weekday_2(date):\n",
    "    return str(datetime.strptime(date, '%d.%m.%Y %H:%M:%S').strftime('%w'))\n",
    "@F.udf\n",
    "def convert_to_hour(date):\n",
    "    return str(datetime.strptime(date, '%d.%m.%Y %H:%M:%S').hour)\n",
    "@F.udf\n",
    "def convert_to_month_1(date):\n",
    "    return str(datetime.strptime(date, '%d.%m.%Y').month)\n",
    "@F.udf\n",
    "def convert_to_month_2(date):\n",
    "    return str(datetime.strptime(date, '%d.%m.%Y %H:%M:%S').month)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dataframe spesifically for delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zurich_delays = df_zurich.withColumn(\"delay_arrive\", delay_arrive).cache()\n",
    "df_zurich_delays = df_zurich_delays.withColumn(\"delay_depart\", delay_depart)\n",
    "df_zurich_delays = df_zurich_delays.withColumn('delay_arrive', convert_to_min(df_zurich_delays.delay_arrive))\n",
    "df_zurich_delays = df_zurich_delays.withColumn('delay_depart', convert_to_min(df_zurich_delays.delay_depart))\n",
    "df_zurich_delays = df_zurich_delays.withColumn(\"TRIP_DATE_month\",convert_to_month_1(df_zurich_delays['TRIP_DATE']))\\\n",
    "                            .withColumn('TRIP_DATE_week_day', convert_to_weekday_1(df_zurich_delays['TRIP_DATE']))\n",
    "    \n",
    "df_zurich_delays = df_zurich_delays.withColumn(\"ACTUAL_ARRIVE_TIME_month\",convert_to_month_2(df_zurich_delays['ACTUAL_ARRIVE_TIME']))\\\n",
    "                            .withColumn('ACTUAL_ARRIVE_TIME_week_day', convert_to_weekday_2(df_zurich_delays['ACTUAL_ARRIVE_TIME']))\\\n",
    "                            .withColumn(\"ACTUAL_ARRIVE_TIME_hour\",convert_to_hour(df_zurich_delays['ACTUAL_ARRIVE_TIME']))\n",
    "\n",
    "df_zurich_delays = df_zurich_delays.withColumn(\"ACTUAL_DEPART_TIME_month\",convert_to_month_2(df_zurich_delays['ACTUAL_DEPART_TIME']))\\\n",
    "                            .withColumn('ACTUAL_DEPART_TIME_week_day', convert_to_weekday_2(df_zurich_delays['ACTUAL_DEPART_TIME']))\\\n",
    "                            .withColumn(\"ACTUAL_DEPART_TIME_hour\",convert_to_hour(df_zurich_delays['ACTUAL_DEPART_TIME']))\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import clusters obtained in Data Analysis notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_num(s, clusters):\n",
    "    for k, v in clusters.items():\n",
    "        if s in clusters[k]:\n",
    "            return k\n",
    "    return None\n",
    "\n",
    "def read_clusters(file_name):\n",
    "    with open('clusters/' + file_name, 'r') as f:\n",
    "        clusters = json.load(f)\n",
    "    return clusters\n",
    "\n",
    "cluster_SERVICE_TYPE = read_clusters('SERVICE_TYPE.json')\n",
    "cluster_OPERATOR_ID = read_clusters('OPERATOR_ID.json')\n",
    "cluster_STATION_ID = read_clusters('STATION_ID.json')\n",
    "\n",
    "cluster_ACTUAL_ARRIVE_TIME_month = read_clusters('ACTUAL_ARRIVE_TIME_month.json')\n",
    "cluster_ACTUAL_ARRIVE_TIME_hour = read_clusters('ACTUAL_ARRIVE_TIME_hour.json')\n",
    "cluster_ACTUAL_ARRIVE_TIME_week_day = read_clusters('ACTUAL_ARRIVE_TIME_week_day.json')\n",
    "\n",
    "cluster_ACTUAL_DEPART_TIME_month = read_clusters('ACTUAL_DEPART_TIME_month.json')\n",
    "cluster_ACTUAL_DEPART_TIME_hour = read_clusters('ACTUAL_DEPART_TIME_hour.json')\n",
    "cluster_ACTUAL_DEPART_TIME_week_day = read_clusters('ACTUAL_DEPART_TIME_week_day.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrive_distribution(arrive = df_zurich_full, date=None, time=None, trip_id=None, service_type=None, operator_id=None, transport_type=None, station_id=None):\n",
    "    \"\"\" Get arrival delay probability and arrival delay distribution coefficients\n",
    "    \n",
    "    This method calculates the arrival delay probability and it calculates the exponential distribution coefficients\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arrive: spark dataframe\n",
    "        As default we get the full SBB dataset to calculate the probability\n",
    "    date: string\n",
    "        Date in format %d.%m.%Y\n",
    "    time: string\n",
    "        Time in format %H:%M\n",
    "    trip_id: string\n",
    "        Id of the trip\n",
    "    service_type: string\n",
    "        Type of service of the trip\n",
    "    operator_id: string\n",
    "        Operator id of the trip\n",
    "    transport_type: string\n",
    "        Transport type of the trip\n",
    "    station_id: string\n",
    "        Station ID\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    arrive_delay_distribution: tuple\n",
    "        Coefficients of the exponential distribution\n",
    "    arrive_delay_probability: float\n",
    "        Probability of this arrival setting to be delayed\n",
    "    \"\"\"\n",
    "    \n",
    "    # extract date information\n",
    "    if date:\n",
    "        week_day = str(datetime.strptime(date, '%d.%m.%Y').strftime('%w'))\n",
    "        month = str(datetime.strptime(date, '%d.%m.%Y').month)\n",
    "    if time:\n",
    "        hour = str(datetime.strptime(time, '%H:%M').hour)\n",
    "\n",
    "    if trip_id:\n",
    "        arrive = arrive.filter(arrive.TRIP_ID==trip_id).cache()\n",
    "    if transport_type:\n",
    "        arrive = arrive.filter(arrive.TRANSPORT_TYPE==transport_type).cache()\n",
    "    \n",
    "    oi_cn = get_cluster_num(operator_id, cluster_OPERATOR_ID)\n",
    "    if oi_cn: arrive = arrive.where(arrive.OPERATOR_ID.isin(cluster_OPERATOR_ID[oi_cn])).cache()\n",
    "\n",
    "    st_cn = get_cluster_num(service_type, cluster_SERVICE_TYPE)\n",
    "    if st_cn: arrive = arrive.where(arrive.SERVICE_TYPE.isin(cluster_SERVICE_TYPE[st_cn])).cache()\n",
    "\n",
    "        \n",
    "    si_cn = get_cluster_num(station_id, cluster_STATION_ID)\n",
    "    if si_cn: arrive = arrive.where(arrive.STATION_ID.isin(cluster_STATION_ID[si_cn])).cache()\n",
    "    \n",
    "    aat_m_cn = get_cluster_num(month, cluster_ACTUAL_ARRIVE_TIME_month)\n",
    "    if aat_m_cn: arrive = arrive.where(arrive.ACTUAL_ARRIVE_TIME_month.isin(cluster_ACTUAL_ARRIVE_TIME_month[aat_m_cn])).cache()\n",
    "        \n",
    "    aat_h_cn = get_cluster_num(hour, cluster_ACTUAL_ARRIVE_TIME_hour)\n",
    "    if aat_h_cn: arrive = arrive.where(arrive.ACTUAL_ARRIVE_TIME_hour.isin(cluster_ACTUAL_ARRIVE_TIME_hour[aat_h_cn])).cache()\n",
    "        \n",
    "    aat_wd_cn = get_cluster_num(week_day, cluster_ACTUAL_ARRIVE_TIME_week_day)\n",
    "    if aat_wd_cn: arrive = arrive.where(arrive.ACTUAL_ARRIVE_TIME_week_day.isin(cluster_ACTUAL_ARRIVE_TIME_week_day[aat_wd_cn])).cache()\n",
    "\n",
    "    # sum of all arrival trips\n",
    "    sum_arrive_trips = arrive.count()\n",
    "\n",
    "    # sum of all delayed trips\n",
    "    arrive = arrive.filter('delay_arrive > 0')\n",
    "    sum_delay_arrive_trips = arrive.count()\n",
    "\n",
    "    # get probabilities of arrival delay\n",
    "    arrive_delay_probability = sum_delay_arrive_trips/sum_arrive_trips\n",
    "    data = arrive.select('delay_arrive').toPandas()\n",
    "    arrive_delay_distribution = stats.expon.fit(np.array(list(map(int, data['delay_arrive'].values))), floc=0, scale=1)\n",
    "\n",
    "    return arrive_delay_distribution, arrive_delay_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of catching the next trip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are calculating the probability of catching the next trip. We know the distribution of arrival delays, as well as the time difference between this and the next trip that make a connection. Also, we use the probability of arrival delay to be delayed. After the exploring following papers: \n",
    "- [Stochastic Modelling of Train Delays and Delay Propagation in Stations](https://repository.tudelft.nl/islandora/object/uuid:caa72522-26b1-4088-afc0-59c6e5c346f6/datastream/OBJ/download)\n",
    "- [Adi Botea, Stefano Braghin, \"Contingent versus Deterministic Plans in Multi-Modal Journey Planning\". ICAPS 2015: 268-272](https://dl.acm.org/citation.cfm?id=3038699)\n",
    "- [Mathematical modeling and methods for rescheduling\n",
    "trains under disrupted operations](https://tel.archives-ouvertes.fr/tel-00453640/document)\n",
    "- [Adi Botea, Stefano Braghin, \"Contingent versus Deterministic Plans in Multi-Modal Journey Planning\". ICAPS 2015: 268-272.](https://dl.acm.org/citation.cfm?id=3038699)\n",
    "- [Adi Botea, Evdokia Nikolova, Michele Berlingerio, \"Multi-Modal Journey Planning in the Presence of Uncertainty\". ICAPS 2013.](https://www.aaai.org/ocs/index.php/ICAPS/ICAPS13/paper/view/6023)\n",
    "\n",
    "we decided to use the next way of calculating the probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability_to_catch(arrive_delay_distribution, timediff, arrive_delay_probability):\n",
    "    \"\"\" Calculating the probability of catching the next trip\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arrive_delay_distribution: tuple\n",
    "        Coefficients of arrive delay exponential distribution\n",
    "    timediff: float\n",
    "        Time difference between this and next trip\n",
    "    arrive_delay_probability: float\n",
    "        Probability of arrival delay\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    p: float\n",
    "        Probability of catching the next trip\n",
    "    \"\"\"\n",
    "    timediff = int(timediff)\n",
    "    quantile = np.arange (0, timediff + 1, 1) \n",
    "    R = stats.expon.cdf(quantile, loc = 0, scale = arrive_delay_distribution[1])\n",
    "    \n",
    "    if arrive_delay_probability == 0:\n",
    "        p = 1\n",
    "    else:\n",
    "        p = (1 - arrive_delay_probability) + arrive_delay_probability * R[timediff]\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidence(connections_info):\n",
    "    \"\"\" Calculate the confidence of the whole route\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    connections_info: dict\n",
    "        Information of how one found route is connected\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    p: float\n",
    "        Confidence of this connection to succeed\n",
    "    \"\"\"\n",
    "    p = 1.0\n",
    "    \n",
    "    for idx in range(len(connections_info)-1):\n",
    "        \n",
    "        arrive_delay_distribution, arrive_delay_probability = None, None\n",
    "\n",
    "        if connections_info[idx]['transport_type'] != 'walk' and connections_info[idx+1]['transport_type'] != 'walk':\n",
    "\n",
    "            arrive_delay_distribution, arrive_delay_probability = arrive_distribution(date=connections_info[idx]['arrive_date'].strftime('%d.%m.%Y'),\n",
    "                                                          time=connections_info[idx]['arrive_date'].strftime('%H:%M'),\n",
    "                                                          trip_id=connections_info[idx]['trip_id'],\n",
    "                                                          service_type=connections_info[idx]['service_type'],\n",
    "                                                          operator_id=connections_info[idx]['operator_id'],\n",
    "                                                          transport_type=connections_info[idx]['transport_type'],\n",
    "                                                          station_id=connections_info[idx]['arrive_station_id'])\n",
    "\n",
    "            timediff = int((connections_info[idx+1]['depart_date']- connections_info[idx]['arrive_date']).seconds)/60\n",
    "\n",
    "            p *= calculate_probability_to_catch(arrive_delay_distribution, timediff, arrive_delay_probability)\n",
    "            \n",
    "        elif connections_info[idx]['transport_type'] == 'walk' and connections_info[idx+1]['transport_type'] != 'walk':\n",
    "            if idx == 0:\n",
    "                arrive_delay_probability = 0\n",
    "                arrive_delay_distribution = stats.expon.fit(np.zeros(1000), floc=0, scale=1)\n",
    "            \n",
    "            timediff = float((connections_info[idx+1]['depart_date'] - connections_info[idx]['arrive_date']).seconds)/60\n",
    "            \n",
    "            p *= calculate_probability_to_catch(arrive_delay_distribution, timediff, arrive_delay_probability)\n",
    "        \n",
    "        elif connections_info[idx]['transport_type'] != 'walk' and connections_info[idx+1]['transport_type'] == 'walk':\n",
    "            arrive_delay_distribution, arrive_delay_probability = arrive_distribution(date=connections_info[idx]['arrive_date'].strftime('%d.%m.%Y'),\n",
    "                                                          time=connections_info[idx]['arrive_date'].strftime('%H:%M'),\n",
    "                                                          trip_id=connections_info[idx]['trip_id'],\n",
    "                                                          service_type=connections_info[idx]['service_type'],\n",
    "                                                          operator_id=connections_info[idx]['operator_id'],\n",
    "                                                          transport_type=connections_info[idx]['transport_type'],\n",
    "                                                          station_id=connections_info[idx]['arrive_station_id'])\n",
    "            timediff = float((connections_info[idx+1]['depart_date']- connections_info[idx]['arrive_date']).seconds)/60\n",
    "\n",
    "            p *= calculate_probability_to_catch(arrive_delay_distribution, timediff, arrive_delay_probability)\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONNECTION GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import TimestampType, IntegerType, StructType, ArrayType, StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TRIP_DATE: string (nullable = true)\n",
      " |-- TRIP_ID: string (nullable = true)\n",
      " |-- OPERATOR_ID: string (nullable = true)\n",
      " |-- OPERATOR_ABK: string (nullable = true)\n",
      " |-- OPERATOR_NAME: string (nullable = true)\n",
      " |-- TRANSPORT_TYPE: string (nullable = true)\n",
      " |-- TRAIN_ID: string (nullable = true)\n",
      " |-- TRAIN_NAME: string (nullable = true)\n",
      " |-- CIRCULATING_ID: string (nullable = true)\n",
      " |-- SERVICE_TYPE: string (nullable = true)\n",
      " |-- ADDITIONAL_DRIVING: string (nullable = true)\n",
      " |-- FAILED: string (nullable = true)\n",
      " |-- STATION_ID: string (nullable = true)\n",
      " |-- STATION_NAME: string (nullable = true)\n",
      " |-- SCHEDULE_ARRIVE_TIME: string (nullable = true)\n",
      " |-- ACTUAL_ARRIVE_TIME: string (nullable = true)\n",
      " |-- ACTUAL_ARRIVE_TIME_STATUS: string (nullable = true)\n",
      " |-- SCHEDULE_DEPART_TIME: string (nullable = true)\n",
      " |-- ACTUAL_DEPART_TIME: string (nullable = true)\n",
      " |-- ACTUAL_DEPART_TIME_STATUS: string (nullable = true)\n",
      " |-- PASSES_BY: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zurich.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mappings f of stations from id to index and index to id\n",
    "#station_index_to_id = df_zurich.select(\"STATION_ID\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "station_index_to_id = list(df_zurich.select('STATION_ID').distinct().toPandas()['STATION_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id_to_index = {}\n",
    "for index, station_id in enumerate(station_index_to_id):\n",
    "    station_id_to_index[station_id] = index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transportation Adjacency Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataframe for trips by cleaning the dataframe for stations in Zurich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define several udf\n",
    "return_index = udf(lambda station_id: station_id_to_index[station_id], IntegerType())\n",
    "return_datetime = udf(lambda date: datetime.strptime(date, \"%d.%m.%Y %H:%M\"), TimestampType())\n",
    "#return_datetime = udf(lambda date: datetime.strptime(date, \"%H:%M\"), TimestampType())\n",
    "\n",
    "# Ignore failed and additional trips\n",
    "df_trips = df_zurich.filter(F.col('ADDITIONAL_DRIVING')=='false')\\\n",
    "                       .filter(F.col('PASSES_BY')=='false')\\\n",
    "                       .select(F.col('TRIP_ID'),\n",
    "                             F.col('TRANSPORT_TYPE'),\n",
    "                             F.col('STATION_ID'),\n",
    "                             return_index('STATION_ID').astype('int').alias('STATION_INDEX'),\n",
    "                             F.col('STATION_NAME'),\n",
    "                             return_datetime(F.col('SCHEDULE_ARRIVE_TIME')).alias('SCHEDULE_ARRIVE_TIME'),\n",
    "                             return_datetime(F.col('SCHEDULE_DEPART_TIME')).alias('SCHEDULE_DEPART_TIME')).cache()\n",
    "\n",
    "#window by trip id and sort by arrival time\n",
    "trip_id_window = Window.partitionBy('TRIP_ID').orderBy(F.asc('SCHEDULE_ARRIVE_TIME'))\n",
    "#keep the order of stations in the trip\n",
    "df_trips = df_trips.withColumn('TRIP_ORDER', F.rank().over(trip_id_window)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TRIP_ID: string (nullable = true)\n",
      " |-- TRANSPORT_TYPE: string (nullable = true)\n",
      " |-- STATION_ID: string (nullable = true)\n",
      " |-- STATION_INDEX: integer (nullable = true)\n",
      " |-- STATION_NAME: string (nullable = true)\n",
      " |-- SCHEDULE_ARRIVE_TIME: timestamp (nullable = true)\n",
      " |-- SCHEDULE_DEPART_TIME: timestamp (nullable = true)\n",
      " |-- TRIP_ORDER: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_trips.printSchema()\n",
    "#df_trips.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create all station pairs connected in a trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TRIP_ID: string (nullable = true)\n",
      " |-- DEPART: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- ARRIVE: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define udf and struct type to get all connected station pairs\n",
    "schema = StructType([\n",
    "    StructField(\"DEPART\", ArrayType(IntegerType()), False),\n",
    "    StructField(\"ARRIVE\", ArrayType(IntegerType()), False)\n",
    "])\n",
    "\n",
    "#iterate over each trip and connect every stations in the trip\n",
    "def return_all_connected_station_pairs(station_indices):\n",
    "    depart = []\n",
    "    arrive = []\n",
    "    for i in range(len(station_indices)):\n",
    "        for j in range(i+1, len(station_indices)):\n",
    "            depart.append(station_indices[i])\n",
    "            arrive.append(station_indices[j])\n",
    "    return [depart, arrive]\n",
    "\n",
    "return_all_connected_station_pairs_udf = F.udf(return_all_connected_station_pairs, schema)\n",
    "\n",
    "# apply udf to df_trips\n",
    "df_connections = df_trips.groupBy('TRIP_ID')\\\n",
    "                       .agg(F.collect_list('STATION_INDEX').alias('STATION_INDEX'))\\\n",
    "                       .withColumn('STATION_INDEX', return_all_connected_station_pairs_udf('STATION_INDEX'))\\\n",
    "                       .select(\"TRIP_ID\", \"STATION_INDEX.DEPART\", \"STATION_INDEX.ARRIVE\")\n",
    "df_connections.printSchema()\n",
    "# df_connections.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build transportation matrix which is a adjacency matrix for a directed graph thath shows if a station is reachable from another station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "transportation_matrix = np.zeros((len(station_index_to_id),len(station_index_to_id)))\n",
    "\n",
    "# collect all pairs as (depart, arrive)\n",
    "depart = df_connections.select('DEPART').rdd.flatMap(lambda x: x).collect()\n",
    "arrive = df_connections.select('ARRIVE').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# fill conection matrix with pairs\n",
    "depart_list = [item for trip in depart for item in trip]\n",
    "arrive_list = [item for trip in arrive for item in trip]\n",
    "\n",
    "for i in range(len(depart_list)):\n",
    "    transportation_matrix[depart_list[i],arrive_list[i]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk Adjcacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load distance dictionary\n",
    "with open('distance/distance_dictionary.pickle', 'rb') as handle:\n",
    "    distance_dictionary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_delay = 5 # change from one station to another in mins\n",
    "\n",
    "# average walking speed is assumed to be 4.5 km/h\n",
    "# ref: https://www.quora.com/What-is-the-average-walking-speed-of-a-human\n",
    "max_walking_time = 5 # min\n",
    "human_speed = 75 # m/min which corresponds to 4.5 km/h\n",
    "max_walking_distance = human_speed * max_walking_time # as meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_matrix = np.zeros((len(station_index_to_id), len(station_index_to_id)))\n",
    "\n",
    "\n",
    "for station_from, station_to in distance_dictionary:\n",
    "    # check if stations are exist in this day\n",
    "    if str(station_from) in  station_id_to_index and str(station_to) in station_id_to_index:\n",
    "        # check if the distance is acceptable\n",
    "        if distance_dictionary[(station_from, station_to)] <= max_walking_distance:\n",
    "            walk_matrix[station_id_to_index[str(station_from)], station_id_to_index[str(station_to)]] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build connection graph by using two adjacency matrix created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged conenction_matrix and wal_matrix into a one single adjcency matrix of all possible paths\n",
    "connection_matrix = np.logical_or(transportation_matrix, walk_matrix).astype(int)\n",
    "connection_graph = nx.DiGraph(connection_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in nx.all_simple_paths(connection_graph, 670, 122, 2):\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debug the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8503000'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id to station name\n",
    "station_index_to_id[160]\n",
    "df_zurich.filter(\"STATION_ID = '8588078'\").first().STATION_NAME\n",
    "\n",
    "# station name to id\n",
    "i = df_zurich.filter(\"STATION_NAME = 'Zürich HB'\").first().STATION_ID\n",
    "station_id_to_index[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# station name to id\n",
    "i = df_zurich.filter(\"STATION_NAME = 'Zürich, Bahnhofplatz/HB'\").first().STATION_ID\n",
    "station_id_to_index[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# station name to id\n",
    "i = df_zurich.filter(\"STATION_NAME = 'Zürich, Bahnhofstrasse/HB'\").first().STATION_ID\n",
    "station_id_to_index[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIMETABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create timetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips = df_zurich.filter(F.col('ADDITIONAL_DRIVING')=='false')\\\n",
    "                       .filter(F.col('PASSES_BY')=='false')\\\n",
    "                       .select(F.col('OPERATOR_ID'), F.col('SERVICE_TYPE'),F.col('TRIP_ID'),\n",
    "                             F.col('TRANSPORT_TYPE'),\n",
    "                             F.col('STATION_ID'),\n",
    "                             return_index('STATION_ID').astype('int').alias('STATION_INDEX'),\n",
    "                             F.col('STATION_NAME'),\n",
    "                             return_datetime(F.col('SCHEDULE_ARRIVE_TIME')).alias('SCHEDULE_ARRIVE_TIME'),\n",
    "                             return_datetime(F.col('SCHEDULE_DEPART_TIME')).alias('SCHEDULE_DEPART_TIME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TRIP_ID: string (nullable = true)\n",
      " |-- OPERATOR_ID: string (nullable = true)\n",
      " |-- SERVICE_TYPE: string (nullable = true)\n",
      " |-- TRANSPORT_TYPE: string (nullable = true)\n",
      " |-- departure_station_id: string (nullable = true)\n",
      " |-- departure_station_index: integer (nullable = true)\n",
      " |-- departure_station_name: string (nullable = true)\n",
      " |-- SCHEDULE_DEPART_TIME: timestamp (nullable = true)\n",
      " |-- arrival_station_id: string (nullable = true)\n",
      " |-- arrival_station_index: integer (nullable = true)\n",
      " |-- arrival_station_name: string (nullable = true)\n",
      " |-- SCHEDULE_ARRIVE_TIME: timestamp (nullable = true)\n",
      "\n",
      "+---------------+-----------+------------+--------------+--------------------+-----------------------+----------------------+--------------------+------------------+---------------------+--------------------+--------------------+\n",
      "|        TRIP_ID|OPERATOR_ID|SERVICE_TYPE|TRANSPORT_TYPE|departure_station_id|departure_station_index|departure_station_name|SCHEDULE_DEPART_TIME|arrival_station_id|arrival_station_index|arrival_station_name|SCHEDULE_ARRIVE_TIME|\n",
      "+---------------+-----------+------------+--------------+--------------------+-----------------------+----------------------+--------------------+------------------+---------------------+--------------------+--------------------+\n",
      "|85:11:18388:001|      85:11|           S|           Zug|             8503306|                    458|             Dietlikon| 2018-06-26 23:14:00|           8503147|                  230|           Stettbach| 2018-06-26 23:17:00|\n",
      "|85:11:18388:001|      85:11|           S|           Zug|             8503306|                    458|             Dietlikon| 2018-06-26 23:14:00|           8503003|                  347|  Zürich Stadelhofen| 2018-06-26 23:22:00|\n",
      "|85:11:18388:001|      85:11|           S|           Zug|             8503306|                    458|             Dietlikon| 2018-06-26 23:14:00|           8503000|                  758|           Zürich HB| 2018-06-26 23:26:00|\n",
      "|85:11:18388:001|      85:11|           S|           Zug|             8503306|                    458|             Dietlikon| 2018-06-26 23:14:00|           8503020|                  225|   Zürich Hardbrücke| 2018-06-26 23:31:00|\n",
      "|85:11:18388:001|      85:11|           S|           Zug|             8503306|                    458|             Dietlikon| 2018-06-26 23:14:00|           8503001|                  543|   Zürich Altstetten| 2018-06-26 23:35:00|\n",
      "|85:11:18388:001|      85:11|           S|           Zug|             8503306|                    458|             Dietlikon| 2018-06-26 23:14:00|           8503509|                  915|           Schlieren| 2018-06-26 23:38:00|\n",
      "|85:11:18388:001|      85:11|           S|           Zug|             8503306|                    458|             Dietlikon| 2018-06-26 23:14:00|           8503512|                  803|         Glanzenberg| 2018-06-26 23:40:00|\n",
      "|85:11:18388:001|      85:11|           S|           Zug|             8503147|                    230|             Stettbach| 2018-06-26 23:18:00|           8503003|                  347|  Zürich Stadelhofen| 2018-06-26 23:22:00|\n",
      "|85:11:18388:001|      85:11|           S|           Zug|             8503147|                    230|             Stettbach| 2018-06-26 23:18:00|           8503000|                  758|           Zürich HB| 2018-06-26 23:26:00|\n",
      "|85:11:18388:001|      85:11|           S|           Zug|             8503147|                    230|             Stettbach| 2018-06-26 23:18:00|           8503020|                  225|   Zürich Hardbrücke| 2018-06-26 23:31:00|\n",
      "+---------------+-----------+------------+--------------+--------------------+-----------------------+----------------------+--------------------+------------------+---------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create timetable of every possible connection by merging df_depart and df_arrive\n",
    "df_depart = df_trips.withColumnRenamed('STATION_ID', 'departure_station_id')\\\n",
    "                                            .withColumnRenamed('STATION_NAME', 'departure_station_name')\\\n",
    "                                            .withColumnRenamed('TRIP_ORDER', 'departure_trip_order')\\\n",
    "                                            .withColumnRenamed('STATION_INDEX', 'departure_station_index')\\\n",
    "                                            .drop('SCHEDULE_ARRIVE_TIME')\n",
    "\n",
    "df_arrive = df_trips.withColumnRenamed('STATION_ID', 'arrival_station_id')\\\n",
    "                                            .withColumnRenamed('STATION_NAME', 'arrival_station_name')\\\n",
    "                                            .withColumnRenamed('TRIP_ORDER', 'arrival_trip_order')\\\n",
    "                                            .withColumnRenamed('STATION_INDEX', 'arrival_station_index')\\\n",
    "                                            .drop('SCHEDULE_DEPART_TIME').drop('type', 'OPERATOR_ID', 'SERVICE_TYPE', 'TRANSPORT_TYPE')\n",
    "\n",
    "\n",
    "timetable = df_depart.join(df_arrive, on=['TRIP_ID'], how='left_outer').drop('departure_trip_order').drop('arrival_trip_order')\n",
    "\n",
    "# drop columns with the same departure and arrival stations\n",
    "mask = timetable.departure_station_name == timetable.arrival_station_name\n",
    "timetable = timetable[~mask]\n",
    "\n",
    "# time reverse connections\n",
    "mask = timetable.SCHEDULE_DEPART_TIME > timetable.SCHEDULE_ARRIVE_TIME\n",
    "timetable = timetable[~mask]\n",
    "\n",
    "timetable.printSchema()\n",
    "timetable.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find fastest connections for each route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load location dictionary\n",
    "with open('distance/location_dictionary.pickle', 'rb') as handle:\n",
    "    location_dictionary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_paths(connection_graph, departure_station_index, arrival_station_index):\n",
    "    \"\"\" Filter paths we need\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    connection_graph: nx.DiGraph  \n",
    "        Connection graph\n",
    "    departure_station_index: int\n",
    "        Index of the departure station\n",
    "    arrival_station_index: int\n",
    "        Index of the arrival station\n",
    "    transportation_matrix: dict\n",
    "        Transportation matrix\n",
    "    walk_matrix: dict\n",
    "        Walk matrix\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    filtered_paths: list\n",
    "        Filtered paths\n",
    "    \"\"\"\n",
    "    filtered_paths = []\n",
    "    for path in nx.all_simple_paths(connection_graph, departure_station_index, arrival_station_index, 2):\n",
    "        \n",
    "        if len(path) == 3:\n",
    "            # check if both connection is by walk or not\n",
    "            depart_index, arrive_index = path[0], path[1]\n",
    "            if walk_matrix[depart_index, arrive_index] == 1:\n",
    "                depart_index, arrive_index = path[1], path[2]\n",
    "                # if both connection is by walk, dont add to the paths\n",
    "                if walk_matrix[depart_index, arrive_index] == 1:\n",
    "                    continue\n",
    "        \n",
    "        filtered_paths.append(path)\n",
    "            \n",
    "    return filtered_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_routes(departure_station, arrival_station, date, hour):\n",
    "    \"\"\" Calculate possible routes based on user input\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    departure_station, \n",
    "        Departure station ID\n",
    "    arrival_station: string\n",
    "        Arrival station ID\n",
    "    date: string\n",
    "        Date in format %Y-%m-%d\n",
    "    hour: string\n",
    "        Hour in format %HH:%MM:%SS\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    all_possible_connections: list of dicts\n",
    "        List of all the possible connections\n",
    "    all_probabilities: list\n",
    "        List of probabilities of each of the connections\n",
    "    \"\"\"\n",
    "    full_date = date + ' ' + hour\n",
    "    # find indices of stations in the graph\n",
    "    departure_station_index = station_id_to_index[departure_station]\n",
    "    arrival_station_index = station_id_to_index[arrival_station]\n",
    "    \n",
    "    all_possible_connections = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    # find all simple paths in the graph\n",
    "    paths = filter_paths(connection_graph, departure_station_index, arrival_station_index)\n",
    "    i = 0\n",
    "    for path in paths:    \n",
    "        print('route:', i)\n",
    "        i = i + 1\n",
    "        print('----------------')\n",
    "        arrival_date = datetime.strptime(full_date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        connections_info = []\n",
    "\n",
    "        route_failed = False\n",
    "        for depart_index, arrive_index in zip(path[:-1], path[1:]):\n",
    "\n",
    "            # check if the path is by walk or by transportation\n",
    "            if walk_matrix[depart_index, arrive_index]:\n",
    "                mins = distance_dictionary[(str(station_index_to_id[depart_index]), str(station_index_to_id[arrive_index]))] / human_speed\n",
    "\n",
    "                departure_date = arrival_date \n",
    "                arrival_date = departure_date + timedelta(minutes=mins)\n",
    "\n",
    "                connections_info.append({'depart_station_id': station_index_to_id[depart_index] , \n",
    "                                         'arrive_station_id': station_index_to_id[arrive_index]  , \n",
    "                                         'depart_date': departure_date,\n",
    "                                         'arrive_date': arrival_date,\n",
    "                                         'transport_type': 'walk',\n",
    "                                         'trip_id': None,\n",
    "                                         'operator_id':None,\n",
    "                                         'service_type': None})\n",
    "\n",
    "\n",
    "            else:\n",
    "                \n",
    "                # add walking time to change stations \n",
    "                arrival_date = arrival_date + timedelta(minutes=transfer_delay)\n",
    "                \n",
    "                # find earliest departure \n",
    "                #connection = timetable.filter((F.col('departure_station_index') == depart_index) & (F.col('arrival_station_index') == arrive_index) & (F.col('SCHEDULE_DEPART_TIME') >= arrival_date.strftime('%Y-%m-%d %H:%M:%S'))).first()\n",
    "                connection = timetable.filter((F.col('departure_station_index') == depart_index) & (F.col('arrival_station_index') == arrive_index) & (F.col('SCHEDULE_DEPART_TIME') >= arrival_date)).first()\n",
    "                if connection:\n",
    "                    arrival_date = connection.SCHEDULE_ARRIVE_TIME\n",
    "\n",
    "                    connections_info.append({'depart_station_id': connection.departure_station_id, \n",
    "                                             'arrive_station_id': connection.arrival_station_id, \n",
    "                                             'depart_date': connection.SCHEDULE_DEPART_TIME, \n",
    "                                             'arrive_date': arrival_date, \n",
    "                                             'transport_type': connection.TRANSPORT_TYPE,\n",
    "                                             'trip_id': connection.TRIP_ID,\n",
    "                                             'operator_id': connection.OPERATOR_ID,\n",
    "                                             'service_type': connection.SERVICE_TYPE})\n",
    "                else:\n",
    "                    print('route failed')\n",
    "                    route_failed = True\n",
    "                    break\n",
    "\n",
    "        if not route_failed:            \n",
    "            p = calculate_confidence(connections_info)\n",
    "        else: \n",
    "            p = 0\n",
    "        \n",
    "        all_possible_connections.append(connections_info)\n",
    "        all_probabilities.append(p)\n",
    "\n",
    "        for connection in connections_info:\n",
    "            print('departure: ',connection['depart_station_id'], 'arrival: ',connection['arrive_station_id'], 'departure_time: ', connection['depart_date'].strftime('%Y-%m-%d %H:%M:%S'), 'arrival_time: ', connection['arrive_date'].strftime('%Y-%m-%d %H:%M:%S'),'transport_type: ', connection['transport_type'])\n",
    "        \n",
    "        \n",
    "        print(f\"confidence = {p}\")\n",
    "        print('----------------')\n",
    "        \n",
    "    # add Lon and Lat\n",
    "    for ci in all_possible_connections:\n",
    "        for trip in ci:\n",
    "            trip['depart_station_id_LON'] =  location_dictionary[trip['depart_station_id']][0]#stations_df.filter(stations_df.station_id == trip['depart_station_id']).select('x_coordinate').collect()[0].x_coordinate\n",
    "            trip['depart_station_id_LAT'] = location_dictionary[trip['depart_station_id']][1]#stations_df.filter(stations_df.station_id == trip['depart_station_id']).select('y_coordinate').collect()[0].y_coordinate\n",
    "            trip['arrive_station_id_LON'] = location_dictionary[trip['arrive_station_id']][0]#stations_df.filter(stations_df.station_id == trip['arrive_station_id']).select('x_coordinate').collect()[0].x_coordinate\n",
    "            trip['arrive_station_id_LAT'] = location_dictionary[trip['arrive_station_id']][1]#stations_df.filter(stations_df.station_id == trip['arrive_station_id']).select('y_coordinate').collect()[0].y_coordinate\n",
    "     \n",
    "    max_confidence_indices = np.argsort(all_probabilities)[::-1]\n",
    "    \n",
    "    all_possible_connections = np.asarray(all_possible_connections)\n",
    "    all_possible_connections = all_possible_connections[max_confidence_indices]\n",
    "    \n",
    "    all_probabilities = np.asarray(all_probabilities)\n",
    "    all_probabilities = all_probabilities[max_confidence_indices]\n",
    "    \n",
    "    return list(all_possible_connections), list(all_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "route: 0\n",
      "----------------\n",
      "route failed\n",
      "departure:  8503000 arrival:  8503202 departure_time:  2018-06-26 23:07:00 arrival_time:  2018-06-26 23:23:00 transport_type:  Zug\n",
      "confidence = 0\n",
      "----------------\n",
      "route: 1\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503006 departure_time:  2018-06-26 21:37:00 arrival_time:  2018-06-26 21:44:00 transport_type:  Zug\n",
      "departure:  8503006 arrival:  8503016 departure_time:  2018-06-26 23:52:00 arrival_time:  2018-06-26 23:56:00 transport_type:  Zug\n",
      "confidence = 1.0\n",
      "----------------\n",
      "route: 2\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503307 departure_time:  2018-06-26 21:49:00 arrival_time:  2018-06-26 22:09:00 transport_type:  Zug\n",
      "departure:  8503307 arrival:  8503016 departure_time:  2018-06-26 22:26:00 arrival_time:  2018-06-26 22:31:00 transport_type:  Zug\n",
      "confidence = 0.9999880327084439\n",
      "----------------\n",
      "route: 3\n",
      "----------------\n",
      "route failed\n",
      "departure:  8503000 arrival:  8503015 departure_time:  2018-06-26 23:44:00 arrival_time:  2018-06-26 23:47:00 transport_type:  Zug\n",
      "confidence = 0\n",
      "----------------\n",
      "route: 4\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503011 departure_time:  2018-06-26 23:07:00 arrival_time:  2018-06-26 23:09:00 transport_type:  Zug\n",
      "departure:  8503011 arrival:  8503016 departure_time:  2018-06-26 23:34:00 arrival_time:  2018-06-26 23:56:00 transport_type:  Zug\n",
      "confidence = 0.9980695458637723\n",
      "----------------\n",
      "route: 5\n",
      "----------------\n",
      "route failed\n",
      "departure:  8503000 arrival:  8503201 departure_time:  2018-06-26 23:07:00 arrival_time:  2018-06-26 23:20:00 transport_type:  Zug\n",
      "confidence = 0\n",
      "----------------\n",
      "route: 6\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503009 departure_time:  2018-06-26 23:07:00 arrival_time:  2018-06-26 23:15:00 transport_type:  Zug\n",
      "departure:  8503009 arrival:  8503016 departure_time:  2018-06-26 23:28:00 arrival_time:  2018-06-26 23:56:00 transport_type:  Zug\n",
      "confidence = 0.961225792168278\n",
      "----------------\n",
      "route: 7\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503200 departure_time:  2018-06-26 23:07:00 arrival_time:  2018-06-26 23:17:00 transport_type:  Zug\n",
      "departure:  8503200 arrival:  8503016 departure_time:  2018-06-26 23:26:00 arrival_time:  2018-06-26 23:56:00 transport_type:  Zug\n",
      "confidence = 0.8946007754381357\n",
      "----------------\n",
      "route: 8\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503010 departure_time:  2018-06-26 23:07:00 arrival_time:  2018-06-26 23:12:00 transport_type:  Zug\n",
      "departure:  8503010 arrival:  8503016 departure_time:  2018-06-26 23:33:00 arrival_time:  2018-06-26 23:56:00 transport_type:  Zug\n",
      "confidence = 0.9740653123038807\n",
      "----------------\n",
      "route: 9\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503016 departure_time:  2018-06-26 17:09:00 arrival_time:  2018-06-26 17:19:00 transport_type:  Zug\n",
      "confidence = 1.0\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "departure_station_id = df_zurich.filter(\"STATION_NAME = '\" + departure_station + \"'\").first().STATION_ID\n",
    "arrival_station_id = df_zurich.filter(\"STATION_NAME = '\" + arrival_station + \"'\").first().STATION_ID\n",
    "all_possible_connections, all_probabilities = calculate_routes(departure_station=departure_station_id, arrival_station=arrival_station_id, date=date, hour=hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'depart_station_id': '8503000',\n",
       "   'arrive_station_id': '8503016',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 17, 9),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 17, 19),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:2277:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'IR',\n",
       "   'depart_station_id_LON': 8.540192,\n",
       "   'depart_station_id_LAT': 47.378177,\n",
       "   'arrive_station_id_LON': 8.562386,\n",
       "   'arrive_station_id_LAT': 47.450383}],\n",
       " [{'depart_station_id': '8503000',\n",
       "   'arrive_station_id': '8503006',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 21, 37),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 21, 44),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:18982:002',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.540192,\n",
       "   'depart_station_id_LAT': 47.378177,\n",
       "   'arrive_station_id_LON': 8.544115,\n",
       "   'arrive_station_id_LAT': 47.411529},\n",
       "  {'depart_station_id': '8503006',\n",
       "   'arrive_station_id': '8503016',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 23, 52),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 23, 56),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:20490:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.544115,\n",
       "   'depart_station_id_LAT': 47.411529,\n",
       "   'arrive_station_id_LON': 8.562386,\n",
       "   'arrive_station_id_LAT': 47.450383}],\n",
       " [{'depart_station_id': '8503000',\n",
       "   'arrive_station_id': '8503307',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 21, 49),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 22, 9),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:18782:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.540192,\n",
       "   'depart_station_id_LAT': 47.378177,\n",
       "   'arrive_station_id_LON': 8.626199,\n",
       "   'arrive_station_id_LAT': 47.438564},\n",
       "  {'depart_station_id': '8503307',\n",
       "   'arrive_station_id': '8503016',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 22, 26),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 22, 31),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:20487:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.626199,\n",
       "   'depart_station_id_LAT': 47.438564,\n",
       "   'arrive_station_id_LON': 8.562386,\n",
       "   'arrive_station_id_LAT': 47.450383}],\n",
       " [{'depart_station_id': '8503000',\n",
       "   'arrive_station_id': '8503011',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 23, 7),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 23, 9),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:18889:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.540192,\n",
       "   'depart_station_id_LAT': 47.378177,\n",
       "   'arrive_station_id_LON': 8.523462,\n",
       "   'arrive_station_id_LAT': 47.371472},\n",
       "  {'depart_station_id': '8503011',\n",
       "   'arrive_station_id': '8503016',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 23, 34),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 23, 56),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:20490:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.523462,\n",
       "   'depart_station_id_LAT': 47.371472,\n",
       "   'arrive_station_id_LON': 8.562386,\n",
       "   'arrive_station_id_LAT': 47.450383}],\n",
       " [{'depart_station_id': '8503000',\n",
       "   'arrive_station_id': '8503010',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 23, 7),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 23, 12),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:18889:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.540192,\n",
       "   'depart_station_id_LAT': 47.378177,\n",
       "   'arrive_station_id_LON': 8.530805,\n",
       "   'arrive_station_id_LAT': 47.364099},\n",
       "  {'depart_station_id': '8503010',\n",
       "   'arrive_station_id': '8503016',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 23, 33),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 23, 56),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:20490:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.530805,\n",
       "   'depart_station_id_LAT': 47.364099,\n",
       "   'arrive_station_id_LON': 8.562386,\n",
       "   'arrive_station_id_LAT': 47.450383}],\n",
       " [{'depart_station_id': '8503000',\n",
       "   'arrive_station_id': '8503009',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 23, 7),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 23, 15),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:18889:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.540192,\n",
       "   'depart_station_id_LAT': 47.378177,\n",
       "   'arrive_station_id_LON': 8.533588,\n",
       "   'arrive_station_id_LAT': 47.34744},\n",
       "  {'depart_station_id': '8503009',\n",
       "   'arrive_station_id': '8503016',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 23, 28),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 23, 56),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:20490:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.533588,\n",
       "   'depart_station_id_LAT': 47.34744,\n",
       "   'arrive_station_id_LON': 8.562386,\n",
       "   'arrive_station_id_LAT': 47.450383}],\n",
       " [{'depart_station_id': '8503000',\n",
       "   'arrive_station_id': '8503200',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 23, 7),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 23, 17),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:18889:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.540192,\n",
       "   'depart_station_id_LAT': 47.378177,\n",
       "   'arrive_station_id_LON': 8.547999,\n",
       "   'arrive_station_id_LAT': 47.324428},\n",
       "  {'depart_station_id': '8503200',\n",
       "   'arrive_station_id': '8503016',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 23, 26),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 23, 56),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:20490:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.547999,\n",
       "   'depart_station_id_LAT': 47.324428,\n",
       "   'arrive_station_id_LON': 8.562386,\n",
       "   'arrive_station_id_LAT': 47.450383}],\n",
       " [{'depart_station_id': '8503000',\n",
       "   'arrive_station_id': '8503201',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 23, 7),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 23, 20),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:18889:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.540192,\n",
       "   'depart_station_id_LAT': 47.378177,\n",
       "   'arrive_station_id_LON': 8.555151,\n",
       "   'arrive_station_id_LAT': 47.307133}],\n",
       " [{'depart_station_id': '8503000',\n",
       "   'arrive_station_id': '8503015',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 23, 44),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 23, 47),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:20490:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.540192,\n",
       "   'depart_station_id_LAT': 47.378177,\n",
       "   'arrive_station_id_LON': 8.529359,\n",
       "   'arrive_station_id_LAT': 47.393032}],\n",
       " [{'depart_station_id': '8503000',\n",
       "   'arrive_station_id': '8503202',\n",
       "   'depart_date': datetime.datetime(2018, 6, 26, 23, 7),\n",
       "   'arrive_date': datetime.datetime(2018, 6, 26, 23, 23),\n",
       "   'transport_type': 'Zug',\n",
       "   'trip_id': '85:11:18889:001',\n",
       "   'operator_id': '85:11',\n",
       "   'service_type': 'S',\n",
       "   'depart_station_id_LON': 8.540192,\n",
       "   'depart_station_id_LAT': 47.378177,\n",
       "   'arrive_station_id_LON': 8.564755,\n",
       "   'arrive_station_id_LAT': 47.295975}]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_possible_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 0.9999880327084439,\n",
       " 0.9980695458637723,\n",
       " 0.9740653123038807,\n",
       " 0.961225792168278,\n",
       " 0.8946007754381357,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the visualization, please run the whole notebook and open the: http://0.0.0.0:5000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_html = \"\"\"\n",
    "<!doctype html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "  <link rel=\"stylesheet\" href=\"https://cdn.rawgit.com/openlayers/openlayers.github.io/master/en/v5.3.0/css/ol.css\"\n",
    "    type=\"text/css\">\n",
    "  <script src=\"https://cdn.rawgit.com/openlayers/openlayers.github.io/master/en/v5.3.0/build/ol.js\"></script>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "  <div style=\"position: absolute; top: 10px; right: 10px; z-index: 100; background: white; padding: 8px;\">\n",
    "  <input type=\"text\" placeholder=\"Start Station ID...\" id=\"start_station_id\" />\n",
    "  <input type=\"text\" placeholder=\"End Station ID...\" id=\"end_station_id\" />\n",
    "  <input type=\"text\" placeholder=\"yyyy-mm-dd\" id=\"in_date\" />\n",
    "  <input type=\"text\" placeholder=\"HH:MM:SS\" id=\"in_time\" />\n",
    "  <button id=\"search\">Show</button>\n",
    "  <div id=\"message\"></div>\n",
    "</div>\n",
    "\n",
    "  <div id=\"map\" style=\"width: 100%; height: 100%\"></div>\n",
    "\n",
    "  <script type=\"text/javascript\">\n",
    "    var features = [];\n",
    "    var vectorLayer = new ol.layer.Vector({\n",
    "      style: function (feature, resolution) {\n",
    "        return feature.get('style');\n",
    "      },\n",
    "    });\n",
    "    var map = new ol.Map({\n",
    "      target: 'map',\n",
    "      layers: [\n",
    "        new ol.layer.Tile({\n",
    "          source: new ol.source.OSM()\n",
    "        }),\n",
    "      ],\n",
    "      view: new ol.View({\n",
    "        center: ol.proj.fromLonLat([8.540192, 47.378177]),\n",
    "        zoom: 14\n",
    "      })\n",
    "    });\n",
    "    map.addLayer(vectorLayer);\n",
    "\n",
    "    function addLine(start, final, color) {\n",
    "      var lineString = new ol.geom.LineString([start, final]);\n",
    "      lineString.transform('EPSG:4326', 'EPSG:3857');\n",
    "      var feature = new ol.Feature({\n",
    "        geometry: lineString,\n",
    "      });\n",
    "      feature.setStyle(new ol.style.Style({\n",
    "        stroke: new ol.style.Stroke({\n",
    "          color: color,\n",
    "          width: 5\n",
    "        })\n",
    "      }));\n",
    "      features.push(feature);\n",
    "      vectorLayer.setSource(\n",
    "        new ol.source.Vector({\n",
    "          features: features,\n",
    "        })\n",
    "      );\n",
    "    }\n",
    "\n",
    "    document.getElementById('search').addEventListener('click', function() {\n",
    "      var start_station_id = document.getElementById('start_station_id').value;\n",
    "      var end_station_id = document.getElementById('end_station_id').value;\n",
    "      var in_date = document.getElementById('in_date').value;\n",
    "      var in_time = document.getElementById('in_time').value;\n",
    "\n",
    "      var xhttp = new XMLHttpRequest();\n",
    "\n",
    "      xhttp.onreadystatechange = function() {\n",
    "        if (this.readyState == 4 && this.status == 200) {\n",
    "          var data = JSON.parse(this.responseText);\n",
    "\n",
    "          data.lines.forEach(function(line) {\n",
    "            addLine(line.start, line.end, line.color);\n",
    "          });\n",
    "          document.getElementById(\"message\").innerHTML = data.message;\n",
    "        }\n",
    "      };\n",
    "\n",
    "      xhttp.open('GET', '/search?start=' + start_station_id + '&end=' + end_station_id + '&date=' + in_date + '&time=' + in_time, true);\n",
    "      xhttp.send();\n",
    "    });\n",
    "\n",
    "    // addLine([8.540192, 47.378177], [8.540192, 47.478177], '#00ff00');\n",
    "    // addLine([8.540192, 47.378177], [8.540192, 47.278177], '#ff0000');\n",
    "  </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here...\n",
      "Ajax call executed! Start 8503000, end 8503016\n",
      "route: 0\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503202 departure_time:  2018-06-26 14:21:00 arrival_time:  2018-06-26 14:38:00 transport_type:  Zug\n",
      "departure:  8503202 arrival:  8503016 departure_time:  2018-06-26 23:22:00 arrival_time:  2018-06-26 23:56:00 transport_type:  Zug\n",
      "confidence = 1.0\n",
      "----------------\n",
      "route: 1\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503006 departure_time:  2018-06-26 05:49:00 arrival_time:  2018-06-26 05:56:00 transport_type:  Zug\n",
      "departure:  8503006 arrival:  8503016 departure_time:  2018-06-26 08:22:00 arrival_time:  2018-06-26 08:26:00 transport_type:  Zug\n",
      "confidence = 1.0\n",
      "----------------\n",
      "route: 2\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503307 departure_time:  2018-06-26 05:49:00 arrival_time:  2018-06-26 06:09:00 transport_type:  Zug\n",
      "departure:  8503307 arrival:  8503016 departure_time:  2018-06-26 13:56:00 arrival_time:  2018-06-26 14:01:00 transport_type:  Zug\n",
      "confidence = 1.0\n",
      "----------------\n",
      "route: 3\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503015 departure_time:  2018-06-26 08:14:00 arrival_time:  2018-06-26 08:17:00 transport_type:  Zug\n",
      "departure:  8503015 arrival:  8503016 departure_time:  2018-06-26 23:47:00 arrival_time:  2018-06-26 23:56:00 transport_type:  Zug\n",
      "confidence = 1.0\n",
      "----------------\n",
      "route: 4\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503011 departure_time:  2018-06-26 14:21:00 arrival_time:  2018-06-26 14:24:00 transport_type:  Zug\n",
      "departure:  8503011 arrival:  8503016 departure_time:  2018-06-26 23:34:00 arrival_time:  2018-06-26 23:56:00 transport_type:  Zug\n",
      "confidence = 1.0\n",
      "----------------\n",
      "route: 5\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503201 departure_time:  2018-06-26 14:21:00 arrival_time:  2018-06-26 14:35:00 transport_type:  Zug\n",
      "departure:  8503201 arrival:  8503016 departure_time:  2018-06-26 23:23:00 arrival_time:  2018-06-26 23:56:00 transport_type:  Zug\n",
      "confidence = 1.0\n",
      "----------------\n",
      "route: 6\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503009 departure_time:  2018-06-26 14:21:00 arrival_time:  2018-06-26 14:30:00 transport_type:  Zug\n",
      "departure:  8503009 arrival:  8503016 departure_time:  2018-06-26 23:28:00 arrival_time:  2018-06-26 23:56:00 transport_type:  Zug\n",
      "confidence = 1.0\n",
      "----------------\n",
      "route: 7\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503200 departure_time:  2018-06-26 14:21:00 arrival_time:  2018-06-26 14:32:00 transport_type:  Zug\n",
      "departure:  8503200 arrival:  8503016 departure_time:  2018-06-26 23:26:00 arrival_time:  2018-06-26 23:56:00 transport_type:  Zug\n",
      "confidence = 1.0\n",
      "----------------\n",
      "route: 8\n",
      "----------------\n",
      "departure:  8503000 arrival:  8503010 departure_time:  2018-06-26 14:21:00 arrival_time:  2018-06-26 14:27:00 transport_type:  Zug\n",
      "departure:  8503010 arrival:  8503016 departure_time:  2018-06-26 23:33:00 arrival_time:  2018-06-26 23:56:00 transport_type:  Zug\n",
      "confidence = 1.0\n",
      "----------------\n",
      "route: 9\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Jun/2019 15:27:12] \"\u001b[37mGET /search?start=8503000&end=8503016&date=2018-02-14&time=00:00:00 HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "departure:  8503000 arrival:  8503016 departure_time:  2018-06-26 11:07:00 arrival_time:  2018-06-26 11:16:00 transport_type:  Zug\n",
      "confidence = 1.0\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def beautify_trip(trip):\n",
    "    return f\"take a {trip['transport_type']} from {trip['depart_station_id']} at {trip['depart_date'].strftime('%d.%m.%Y %H:%M')} to {trip['arrive_station_id']} at {trip['arrive_date'].strftime('%d.%m.%Y %H:%M')}\"\n",
    "\n",
    "def beautify_print(all_possible_connections, all_probabilities):\n",
    "    colors = [\"green\", \"red\", \"blue\"]\n",
    "    ret_val = \"\"\n",
    "    for i, (p, ci) in enumerate(zip(all_probabilities, all_possible_connections)):\n",
    "        ret_val += f\"Connection {i+1} [{colors[i].upper()}] - Probability {p}:<br/>\"\n",
    "        for j, trip in enumerate(ci): \n",
    "            ret_val += f\"{j+1}) {beautify_trip(trip)} <br/>\"\n",
    "        ret_val += \"<br/><br/>\"\n",
    "    return ret_val\n",
    "\n",
    "def make_lines(all_possible_connections):\n",
    "    out_lines = []\n",
    "    colors = ['#00ff00', '#ff0000', '#0000ff']\n",
    "    for i, (p, ci) in enumerate(zip(all_probabilities, all_possible_connections)):\n",
    "        for j, trip in enumerate(ci): \n",
    "            out_lines.append({ 'start': [ trip['depart_station_id_LON'], trip['depart_station_id_LAT']], 'end': [trip['arrive_station_id_LON'], trip['arrive_station_id_LAT']], 'color': colors[i] })\n",
    "    return out_lines\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    return index_html\n",
    "\n",
    "\n",
    "@app.route('/search', methods=['GET'])\n",
    "def search():\n",
    "    print('here...')\n",
    "    # Grab arguments here\n",
    "    start_arg = request.args.get('start')\n",
    "    end_arg = request.args.get('end')\n",
    "    date_arg = request.args.get('date')\n",
    "    time_arg = request.args.get('time')\n",
    "    \n",
    "    print(f'Ajax call executed! Start {start_arg}, end {end_arg}')\n",
    "    \n",
    "    # Do some processing\n",
    "    #all_possible_connections, all_probabilities = find_route_with_probability(departure_station='8503000', arrival_station='8503016', date='2018-02-14', hour='00:00:00')\n",
    "    all_possible_connections, all_probabilities = calculate_routes(departure_station=start_arg, arrival_station=end_arg, date=date_arg, hour=time_arg)\n",
    "    all_possible_connections, all_probabilities = all_possible_connections[:3], all_probabilities[:3]\n",
    "    status_message = beautify_print(all_possible_connections, all_probabilities)\n",
    "    \n",
    "    out_lines = make_lines(all_possible_connections)\n",
    "    \n",
    "    # Return data in corresponding format\n",
    "    return jsonify({ 'message': status_message, 'lines': out_lines})\n",
    "\n",
    "\n",
    "app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
